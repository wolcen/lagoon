# vi: ft=fluentd
<source>
  # fluentd parameters
  @type  syslog
  @id    router
  @label @router
  tag    "lagoon.#{ENV['CLUSTER_NAME']}.logs.router"
  # syslog parameters
  port         5140
  severity_key severity
  <parse>
    @type       regexp
    # parse HTTP logs based on the haproxy documentation
    # As per the documentation here
    # https://www.haproxy.com/documentation/hapee/1-8r1/onepage/#8.2.3, except
    # we split the frontend_name into its constituent parts as used by
    # openshift.
    expression    /^.{,15} (?<process_name>\w+)\[(?<pid>\d+)\]: (?<client_ip>\S+):(?<client_port>\d+) \[(?<request_date>\S+)\] (?<frontend_name>\S+) (?<backend_type>\S+):(?<container_id>(?<kubernetes_namespace_name>\S+):\S+\/pod:(?<kubernetes_pod_name>[^:]+):(?<kubernetes_container_name>[^:]+)):\S+ (?<TR>[\d-]+)\/(?<Tw>[\d-]+)\/(?<Tc>[\d-]+)\/(?<Tr>[\d-]+)\/(?<Ta>[\d-]+) (?<status_code>\d+) (?<bytes_read>\d+) (?<captured_request_cookie>\S+) (?<captured_response_cookie>\S+) (?<termination_state>\S+) (?<actconn>\d+)\/(?<feconn>\d+)\/(?<beconn>\d+)\/(?<srv_conn>\d+)\/(?<retries>\d+) (?<srv_queue>\d+)\/(?<backend_queue>\d+) "(?<http_request>.+)"/
    time_key      request_date
    time_format   %d/%b/%Y:%T.%L
    types         pid:integer,client_port:integer,TR:integer,Tw:integer,Tc:integer,Tr:integer,Ta:integer,bytes_read:integer,actconn:integer,feconn:integer,beconn:integer,srv_conn:integer,retries:integer,srv_queue:integer,backend_queue:integer
  </parse>
</source>

<label @router>
  # Inject fields in the structure required by the metadata lookup plugin.
  <filter **>
    @type record_transformer
    enable_ruby
    remove_keys kubernetes_namespace_name,kubernetes_pod_name,kubernetes_container_name
    <record>
      kubernetes ${{"namespace_name" => record["kubernetes_namespace_name"], "pod_name" => record["kubernetes_pod_name"], "container_name" => record["kubernetes_container_name"]}}
    </record>
  </filter>
  # Inject more fields in the structure required by the metadata lookup plugin.
  # Note that container_id here does not have to be the real docker container
  # ID. It's only used as a unique cache key.
  <filter **>
    @type record_transformer
    enable_ruby
    remove_keys container_id
    <record>
      docker ${{"container_id" => record["container_id"]}}
    </record>
  </filter>
  # enrich with k8s metadata
  <filter **>
    @type kubernetes_metadata
  </filter>
  # remove the docker container ID field, which is only relevant to the k8s
  # metadata plugin caching, and add the lagoon_project as a top-level key for
  # easy access.
  <filter **>
    @type record_transformer
    enable_ruby
    remove_keys docker
    <record>
      lagoon_project ${record.dig("kubernetes","namespace_labels","lagoon/project")}
    </record>
  </filter>
  # Inject fluentd default "time" field, ms precision. This is used as the log
  # timestamp when read from the queue by the logs-dispatcher.
  <filter **>
    @type record_transformer
    enable_ruby
    <record>
      time "${Time.at(time).strftime('%s.%L')}"
    </record>
  </filter>
  # log to local stdout
  <filter **>
    @type stdout
  </filter>
  # send to rabbitmq
  <match **>
    @type            rabbitmq
    host             broker
    user             "#{ENV['RABBITMQ_USER']}"
    pass             "#{ENV['RABBITMQ_PASS']}"
    routing_key      "lagoon.#{ENV['CLUSTER_NAME']}.logs.router"
    exchange         lagoon
    exchange_type    topic
    exchange_durable true
    content_type     application/json
    <format>
      @type json
    </format>
    <buffer>
      flush_thread_count 8
      flush_interval     5s
    </buffer>
  </match>
</label>
